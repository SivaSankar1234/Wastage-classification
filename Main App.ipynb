{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802e0831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Siva Sankar\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afcdebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_BREDTH = 30\n",
    "IMG_HEIGHT = 60\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e0a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_model(path):\n",
    "\n",
    "    model = load_model('best_waste_classifier.h5')\n",
    "    pic = plt.imread(path)\n",
    "    pic = cv2.resize(pic, (IMG_BREDTH, IMG_HEIGHT))\n",
    "    pic = np.expand_dims(pic, axis=0)\n",
    "    predict_x=model.predict(pic)\n",
    "    print(predict_x)\n",
    "    classes_x=np.argmax(predict_x,axis=1)\n",
    "\n",
    "\n",
    "#     code using PIL\n",
    "#     model = load_model('best_waste_classifier.h5')\n",
    "#     pic1 = plt.imread(path)\n",
    "#     pic = Image.open(path).resize((IMG_BREDTH, IMG_HEIGHT))\n",
    "#     plt.imshow(pic1)\n",
    "#     if model.predict_classes(np.expand_dims(pic, axis=0)) == 0:\n",
    "#         classes = 'ORGANIC'\n",
    "#     elif model.predict_classes(np.expand_dims(pic, axis=0)) == 1:\n",
    "#         classes = 'RECYCLABLE'\n",
    "\n",
    "    return classes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03537f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Siva Sankar\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Siva Sankar\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "[[0.02151746 0.97848254]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(use_model(\"C:/Users/Siva Sankar/Desktop/major-2/plastic3.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b77dc255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_models(img):\n",
    "    model = load_model('best_waste_classifier.h5')\n",
    "    pic = img\n",
    "    pic = cv2.resize(pic, (IMG_BREDTH, IMG_HEIGHT))\n",
    "    \n",
    "    pic = np.expand_dims(pic, axis=0)\n",
    "    predict_x=model.predict(pic)\n",
    "    \n",
    "    classes_x=np.argmax(predict_x,axis=1)\n",
    "    if classes_x[0]==0:\n",
    "        print(\"Organic waste detected\")\n",
    "    else:\n",
    "        print(\"Recyclable waste detected\")\n",
    "        \n",
    "\n",
    "#     code using PIL\n",
    "    model = load_model('best_waste_classifier.h5')\n",
    "    pic1 = plt.imread(path)\n",
    "    pic = Image.open(path).resize((IMG_BREDTH, IMG_HEIGHT))\n",
    "    plt.imshow(pic1)\n",
    "    if model.predict_classes(np.expand_dims(pic, axis=0)) == 0:\n",
    "        classes = 'ORGANIC'\n",
    "    elif model.predict_classes(np.expand_dims(pic, axis=0)) == 1:\n",
    "        classes = 'RECYCLABLE'\n",
    "\n",
    "    return classes_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c14b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import websockets\n",
    "import asyncio\n",
    "\n",
    "async def send_message(message):\n",
    "    async with websockets.connect(\"ws://192.168.168.48:8765\") as websocket:\n",
    "        await websocket.send(message)\n",
    "        response = await websocket.recv()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff60c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the colors to detect waste materials (adjust these values based on your requirements)\n",
    "waste_colors = [(0, 165, 255), (0, 255, 0)]  # Blue and green colors for example\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "i=1\n",
    "while i>0:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if use_models(frame)[0]==0:\n",
    "        asyncio.run(await send_message(\"organic\"))\n",
    "    else:\n",
    "        asyncio.run(await send_message(\"recyclable\"))\n",
    "\n",
    "    # Convert the frame to the HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a mask for the waste colors\n",
    "    mask = np.zeros_like(hsv[:, :, 0])\n",
    "    for color in waste_colors:\n",
    "        lower = np.array([color[0] - 20, 100, 100])\n",
    "        upper = np.array([color[0] + 20, 255, 255])\n",
    "        mask = cv2.bitwise_or(mask, cv2.inRange(hsv, lower, upper))\n",
    "    print(\"2\")\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw bounding boxes and edit the image for detected waste materials\n",
    "    print(len(contours))\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        print(\"3\")\n",
    "        if area > 500:  # Adjust this threshold value based on your requirements\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Edit the image to the size of the detected waste material\n",
    "            roi = frame[y:y + h, x:x + w]\n",
    "            \n",
    "            # You can perform additional processing on the ROI here\n",
    "            print(use_models(roi)[0])\n",
    "            if use_models(roi)[0]==0:\n",
    "                print(\"Organic waste\")\n",
    "                asyncio.run(await send_message(\"organic\"))\n",
    "                break\n",
    "            else:\n",
    "                print(\"Recyclable waste\")\n",
    "                asyncio.run(await send_message(\"recyclable\"))\n",
    "                break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Waste Detection', frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    i-=1\n",
    "\n",
    "# Release the capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8688a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0c6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ae500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6fc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
